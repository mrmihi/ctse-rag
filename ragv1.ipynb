{
 "cells": [
  {
   "cell_type": "code",
   "id": "f6b7353a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:21:23.461830Z",
     "start_time": "2025-05-11T16:21:23.458792Z"
    }
   },
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBW6XKhpcRVHrthjvUBmyLHxTW7DJooWaA\""
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "5e40b3e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:21:37.283734Z",
     "start_time": "2025-05-11T16:21:23.473420Z"
    }
   },
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Instantiate the Encoder\n",
    "encoder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "print(\"✅ Encoder ready, dim =\", encoder.get_sentence_embedding_dimension())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Encoder ready, dim = 384\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "7cdd62a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:22:01.220828Z",
     "start_time": "2025-05-11T16:21:57.606793Z"
    }
   },
   "source": [
    "# Connect to Milvus\n",
    "from pymilvus import connections\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "connections.connect(\n",
    "    alias=\"default\",\n",
    "    host=\"localhost\",\n",
    "    port=\"19530\"\n",
    ")\n",
    "\n",
    "# Set up embedding model\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "93bede4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:21:41.625252Z",
     "start_time": "2025-05-11T16:21:41.534799Z"
    }
   },
   "source": [
    "# Load and split your PDFs\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "folder_path = \"./pdfs\"\n",
    "loader_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "documents = []\n",
    "for fname in os.listdir(folder_path):\n",
    "    if not fname.lower().endswith(\".pdf\"):\n",
    "        continue\n",
    "    path = os.path.join(folder_path, fname)\n",
    "    loader = PyPDFLoader(path)\n",
    "    pages = loader.load_and_split(text_splitter=loader_splitter)\n",
    "    # metadata 'page' comes from loader\n",
    "    documents.extend(pages)\n",
    "\n",
    "print(f\"✅ Loaded and split {len(documents)} chunks from PDFs.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded and split 31 chunks from PDFs.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "be07a14c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:21:47.811593Z",
     "start_time": "2025-05-11T16:21:41.630482Z"
    }
   },
   "source": [
    "from langchain.vectorstores import Milvus\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "# your embedding model (384-dim)\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# index + search config\n",
    "index_params = {\n",
    "    \"index_type\": \"IVF_FLAT\",\n",
    "    \"metric_type\": \"COSINE\",\n",
    "    \"params\": {\"nlist\": 128},       # number of partitions\n",
    "}\n",
    "search_params = {\n",
    "    \"metric_type\": \"COSINE\",\n",
    "    \"params\": {\"nprobe\": 10},       # how many partitions to probe at query time\n",
    "}\n",
    "\n",
    "# upsert into Milvus with IVF_FLAT/COSINE on a 384-dim vector field\n",
    "vectorstore = Milvus.from_documents(\n",
    "    documents,\n",
    "    embeddings,\n",
    "    connection_args={\"host\": \"localhost\", \"port\": \"19530\"},\n",
    "    collection_name=\"pdf_documents\",\n",
    "    index_params=index_params,\n",
    "    search_params=search_params,\n",
    "    drop_old=True,               # overwrite any existing collection\n",
    ")\n",
    "\n",
    "print(\"✅ Upserted documents into Milvus with IVf_FLAT / COSINE (384-dim).\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Upserted documents into Milvus with IVf_FLAT / COSINE (384-dim).\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "7c4ae752",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:21:47.836599Z",
     "start_time": "2025-05-11T16:21:47.822785Z"
    }
   },
   "source": [
    "# Build the RAG chain using Gemini API\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"You are an expert assistant. Use the following context (with page numbers) to answer the user’s question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "1. Summary:  \n",
    "   Provide a succinct explanatory summary (1–2 sentences).\n",
    "\n",
    "2. Key Points:  \n",
    "   List the main supporting details in bullet form. For each bullet, cite the page number in parentheses.\n",
    "\n",
    "Example format:\n",
    "\n",
    "1. Summary:  \n",
    "   The primary purpose of Pinecone is to store and query dense vector embeddings for similarity search (page 12).\n",
    "\n",
    "2. Key Points:  \n",
    "   - Pinecone offers a fully managed vector database service, eliminating infrastructure overhead (page 5).  \n",
    "   - It supports cosine and dot-product similarity metrics for fast nearest-neighbor retrieval (page 8).  \n",
    "   - Integrates seamlessly with popular embedding libraries like SentenceTransformer (page 14).  \n",
    "   - Provides automatic indexing and sharding to scale to billions of vectors (page 20).\n",
    "\n",
    "Now, answer the question below following this format:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.1)\n",
    "\n",
    "# Create RetrievalQA chain\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "print(\"RAG chain with Gemini is ready.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG chain with Gemini is ready.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "11eb1e01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:21:51.382065Z",
     "start_time": "2025-05-11T16:21:47.843395Z"
    }
   },
   "source": [
    "# Test the chain\n",
    "question = \"what are sets?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "\n",
    "print(\"Answer:\\n\", result[\"result\"])\n",
    "print(\"\\nSources:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    src = doc.metadata.get(\"source\", \"unknown\")\n",
    "    pg  = doc.metadata.get(\"page\", \"unknown\")\n",
    "    print(f\" • {src} — page {pg}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      " 1. Summary:\n",
      "Sets are unordered collections that contain only one instance of each distinct value and are similar to arrays, but unlike arrays, they must contain only one data type (page 9).\n",
      "\n",
      "2. Key Points:\n",
      "- Sets are unordered and contain only one of each distinct value (page 9).\n",
      "-  They can be created using `var evenNumbers = Set([2, 4, 6, 8])` or `var oddNumbers: Set = [1,3,5,7]` (page 9).\n",
      "-  Elements can be added using `.insert()` and removed using `.remove()` (page 9).\n",
      "- Sets are a type of collection (page 10).\n",
      "\n",
      "Sources:\n",
      " • ./pdfs/2023-S1-SE4020-Lecture-02-Introduction.pdf — page 8\n",
      " • ./pdfs/2023-S1-SE4020-Lecture-02-Introduction.pdf — page 1\n",
      " • ./pdfs/2023-S1-SE4020-Lecture-02-Introduction.pdf — page 15\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "2ccb462d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T16:21:51.393551Z",
     "start_time": "2025-05-11T16:21:51.391788Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
